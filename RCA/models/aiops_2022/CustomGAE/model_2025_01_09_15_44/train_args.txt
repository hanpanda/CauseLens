loss: 0.04961837388368116. 
dataset: aiops_2022. 
. training samples: 9153. 

model: CustomGAE.
model_file: .
mode: train.
seed: 42.
epoch: 200.
batch_size: 64.
lr: 0.001.
device: cuda.
valid_ratio: 0.0.
dataset: aiops_2022.
data_dir: ../datasets/aiops_2022/graph/.
failure_types: [''].
failure_duration: 15.
train_dates: ['2022-03-20', '2022-03-21', '2022-03-22', '2022-03-24', '2022-03-26', '2022-03-28', '2022-03-29', '2022-03-30', '2022-03-31', '2022-04-01'].
test_dates: None.
used_etypes: ['api2api', 'api2pod'].
nfeat_select: {'api': ['count', 'mean', 'min', 'q10', 'q20', 'q30', 'q40', 'q50', 'q60', 'q70', 'q80', 'q90', 'max'], 'pod': ['container_cpu_usage_seconds', 'container_cpu_cfs_throttled_seconds', 'container_memory_usage_MB', 'container_memory_working_set_MB', 'container_fs_io_time_seconds./dev/vda1', 'container_fs_io_current./dev/vda1', 'container_network_receive_errors.eth0', 'container_network_transmit_errors.eth0', 'container_network_receive_MB.eth0', 'container_network_transmit_MB.eth0', 'container_network_receive_packets_dropped.eth0', 'container_network_transmit_packets_dropped.eth0', 'container_threads', 'count']}.
node_scale_type: nodewise.
edge_scale_type: edgewise.
add_self_loop: False.
edge_reverse: False.
log_before_scale: True.
process_miss: interpolate.
process_extreme: False.
k_sigma: 3.
use_split_info: False.
conv_type: DotGAT.
num_heads: 6.
feat_drop: 0.0.
attn_drop: 0.0.
num_enc_layers: 1.
num_dec_layers: 1.
decoder_type: mlp.
num_etypes: 6.
edge_feats: 1.
etype_feats: 5.
residual: False.
hidden_dim: 10.
proj_feats: 10.
mask: False.
mask_feat_type: mean.
loss_type: mse.
use_edge_feats: True.
use_etype_feats: False.
embedding: True.
recon_ntypes: ['api', 'pod'].
window: 300.
score_type: pred_and_mean.
causal_threshold: 0.3.
ad_threshold: 1.0.
dist_type_for_counterfactual: euclidean.
dist_direction: gt.
threshold_1: 0.
threshold_2: 8.
weight_score: False.
CustomGAE(
  (encoder): GATEncoder(
    (gat_layers): ModuleList(
      (0): myDotGATConv(
        (fc_k): Linear(in_features=10, out_features=60, bias=True)
        (fc_q): Linear(in_features=10, out_features=60, bias=True)
        (fc_v): Linear(in_features=10, out_features=60, bias=True)
        (fc_e): Linear(in_features=1, out_features=60, bias=True)
        (feat_drop): Dropout(p=0.0, inplace=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (activation): LeakyReLU(negative_slope=0.01)
      )
    )
    (linear): Linear(in_features=60, out_features=10, bias=True)
  )
  (attr_decoder): MLP(
    (linears): ModuleList(
      (0): Linear(in_features=10, out_features=30, bias=True)
      (1): Linear(in_features=30, out_features=20, bias=True)
      (2): Linear(in_features=20, out_features=10, bias=True)
    )
  )
  (struct_decoder): InnerProductDecoder()
  (in_projs): ModuleDict(
    (api): Linear(in_features=13, out_features=10, bias=True)
    (pod): Linear(in_features=14, out_features=10, bias=True)
  )
  (out_projs): ModuleDict(
    (api): Linear(in_features=10, out_features=13, bias=True)
    (pod): Linear(in_features=10, out_features=14, bias=True)
  )
  (emb_layer_dict): ModuleDict(
    (api): Embedding(36, 10)
    (pod): Embedding(40, 10)
  )
)
